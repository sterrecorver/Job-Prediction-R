---
title: "Project"
author: "Sterre Corver and Tim van der Valk"
date: "2023-02-22"
output:
  prettydoc::html_pretty:
      theme: leonids
      highlights: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(janitor)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(knitr)
library(tidyr)
library(scales)
library(tidymodels)
library(rpart)
library(ggcorrplot)
library(corrplot)
```

We upload the dataset in R, and make sure that the variable names that consist of more than 1 word, there will be placed an _ between the words. 

```{r}
data <- read.csv("C:/Users/timva/Downloads/Job dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv") %>% clean_names()
```

##Pre-processing
Remove the variabels "...." since they have hte.

```{r}
df <- subset(data, select = -c(employee_count, standard_hours, over18))
```

Now we transform the binary variables answered with yes/no by 1/0, and then reclassify them into factors.

```{r}
df <- df %>%
  mutate(across(c("attrition","over_time"),
                ~ if_else(. == "Yes",1,0))) %>% 
  mutate(across(c("attrition","over_time"),
                ~ as.factor(.)))
```


We continue by reclassifying the nominal and the ordinal variables as factors. For the ordinal vectors we make sure that the order is kept.

```{r}
df <- df %>%  
  mutate(across(c("department", "education_field",
                  "job_role", "marital_status"),~ as.factor(.))) %>%
  mutate(across(c("environment_satisfaction", "job_satisfaction",
                  "relationship_satisfaction",
                  "work_life_balance","business_travel", "education" ,
                  "job_involvement","job_level", "stock_option_level",
                  "performance_rating"),
                ~ as.ordered(.))) %>%
  mutate(business_travel = factor(business_travel, ordered = TRUE,
                                  levels = c("Non-Travel",
                                             "Travel_Rarely","Travel_Frequently")))
```


Now we put the different variables into groups
```{r}
numerical <- c("age", "distance_from_home","hourly_rate",
               "daily_rate", "monthly_rate","monthly_income",
               "percent_salary_hike","years_at_company",
               "years_in_current_role","years_since_last_promotion",
               "years_with_curr_manager","total_working_years",
               "num_companies_worked","training_times_last_year") 

categorical <- c("gender","over_time","department",
                 "education_field", "job_role", "marital_status")

ordinal <- c("environment_satisfaction", "job_satisfaction",
             "relationship_satisfaction","work_life_balance",
             "job_involvement","performance_rating",
             "business_travel", "education","job_level",
             "stock_option_level")
```

```{r}
#creating a train/test split

# Setting the seed for reproducibility
set.seed(1234)

# Creating a train/test split using the `rsample` package
library(rsample)
split <- initial_split(df, prop = 0.8, strata = attrition)
train <- training(split)
test <- testing(split)
```


##Descriptive analysis
We start by looking at the dependent variable in our regression, which is the attrition rate.This is the number of employees that have left te firm divided by the total number of employees at the firm.

```{r}

attrition_counts <- data %>%
  count(attrition)

pie_chart <- ggplot(attrition_counts, aes(x = "", y = n, fill = attrition)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  geom_text(aes(label = paste0(n)), position = position_stack(vjust = 0.5)) +
  labs(title = "Attrition") +
  theme_void()

# Display the pie chart
pie_chart
```

We continue by making a selection of some of the variables, which we selected to use in our analysis. We made this selection by going through literature, and see which according to them, had a significant influence on the attrition rate.

```{r}
subset_data <- data %>%
  select(years_in_current_role, job_role, monthly_income, job_satisfaction, work_life_balance, age, gender)

summary_table <- subset_data %>%
  select(years_in_current_role, monthly_income, job_satisfaction, work_life_balance, age) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "value") %>%
  group_by(variable) %>%
  summarize(mean = mean(value), sd = sd(value)) %>%
  pivot_longer(cols = c("mean", "sd"), names_to = "statistic", values_to = "value") %>%
  pivot_wider(names_from = variable, values_from = value) %>%
  kable()

boxplot_data <- subset_data %>%
  filter(gender != "") %>%
  ggplot(aes(x = gender, y = years_in_current_role, fill = gender)) +
  geom_boxplot() +
  labs(x = "Gender", y = "Years in Current Role", title = "Years in Current Role by Gender") +
  theme_minimal()

histogram_data <- subset_data %>%
  ggplot(aes(x = monthly_income)) +
  geom_histogram(binwidth = 500, fill = "#69b3a2", color = "white") +
  labs(x = "Monthly Income", y = "Count", title = "Histogram of Monthly Income") +
  theme_minimal()

job_counts <- subset_data %>%
  group_by(job_role) %>%
  summarize(count = n()) %>%
  arrange(desc(count))

plot_job_role <-  ggplot(job_counts, aes(x = "", y = count, fill = job_role)) +
                  geom_bar(stat = "identity", width = 1) +
                  coord_polar(theta = "y") +
                  labs(title = "Counts of Job Roles") +
                  theme_void() +
                  theme(legend.position = "bottom")

summary_table
boxplot_data
histogram_data
plot_job_role
```

```{r}
# Define the recipe object with the target variable and all predictors
hr_recipe <- recipe(attrition ~ ., data = train) 

# Update the role of the employee_number variable to "ID"
hr_recipe <- update_role(hr_recipe, "employee_number", new_role = "ID")

# Normalize the numeric variables age, monthly_income, and total_satisfaction
hr_recipe <- step_normalize(hr_recipe, all_numeric_predictors())

# Create dummy variables for all nominal predictors using one-hot encoding
hr_recipe <- step_dummy(hr_recipe, all_nominal_predictors(), one_hot = TRUE)

# Remove near-zero variance predictors among the nominal variables
hr_recipe <- step_nzv(hr_recipe, all_nominal_predictors())

# Remove highly correlated predictors among all variables
hr_recipe <- step_corr(hr_recipe, -all_outcomes())

```

```{r}
# Prepare the recipe for use with the training data
hr_recipe_prep <- prep(hr_recipe, training = train)

# Apply the recipe to the training data and extract the preprocessed data
hr_data_juiced <- juice(hr_recipe_prep)

# Print the summary of the preprocessed data
glimpse(hr_data_juiced)

```

```{r}
# Define a function for post-EDA data processing
post_eda_processing <- function(tbl) {
  tbl %>%
    mutate(total_satisfaction = rowSums(select(., environment_satisfaction:job_involvement))) %>%
    select(-c(distance_from_home, hourly_rate, daily_rate, monthly_rate,
              percent_salary_hike, training_times_last_year, years_at_company))
}

# Apply the post-EDA processing function to the `hr`, `train`, and `test` data frames
df <- post_eda_processing(df)
train <- post_eda_processing(train)
test <- post_eda_processing(test)

```

```{r}
# Build the decision tree model
dectreemodel <- rpart(attrition ~ years_in_current_role + job_role + monthly_income + job_satisfaction + work_life_balance + age + gender,
               data = train,
               method = "class")

# Plot the decision tree
rpart.plot(dectreemodel)

# Predict on the testing set
predictions <- predict(dectreemodel, newdata = test, type = "class")

# Evaluate the model
confusion_matrix <- table(predictions, test$attrition)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(confusion_matrix)
print(paste0("Accuracy: ", round(accuracy, 2)))


#Here, we use the rpart library to build a decision tree model, which can be visualized using the rpart.plot library. We convert the "gender" variable to a factor, split the data into training and testing sets, and fit the model on the training data. We then predict on the testing set and evaluate the model using a confusion matrix and accuracy metric. Note that this is just one possible solution, and there are many other models and techniques you can use to predict "attrition" with these variables.






```

```{r}
# Load the necessary package
library(dplyr)

# Create a new binary variable indicating if job level is lower than education level
df <- df %>%
  mutate(job_level_below_education = ifelse(job_level < education, 1, 0))

# Build a logistic regression model to predict attrition 
model <- glm(attrition ~ job_level_below_education, data = df, family = binomial())

# Display model summary
summary(model)

# Calculate the number of people with attrition = 1 who also have job_level_below_education = 1
n <- sum(df$attrition == 1 & df$job_level_below_education == 1)
cat("Number of people with attrition = 1 and job_level_below_education = 1:", n)

```

```{r}
# create a contingency table
table(df$attrition, df$job_level_below_education)

# create a mosaic plot
mosaicplot(table(df$attrition, df$job_level_below_education), 
           main = "Attrition vs. Job Level Below Education", 
           color = c("#00BFC4", "#F8766D"), 
           ylab = "Attrition", xlab = "Job Level Below Education")

```

```{r}
ggplot(df, aes(x = factor(job_level), fill = factor(attrition))) + 
  geom_bar(position = "fill") +
  facet_wrap(~education) +
  labs(x = "Job Level", y = "Proportion", fill = "Attrition") +
  scale_fill_manual(values = c("green", "red"), labels = c("No", "Yes"))
```

```{r}
library(corrplot)

# Define color palette
my_colors <- colorRampPalette(c("#009E73", "#F0E442", "#0072B2"))(100)

# Set graphical parameters
par(mar = c(0, 0, 0, 0), bg = "#F7FBFF")

# Plot correlation matrix with customized parameters
corrplot(cor(df[,numerical]), method="circle", order="hclust",
         col=my_colors, tl.col="#696969", tl.srt=45, tl.cex=0.8,
         addCoef.col="#696969", addCoef.cex=0.6)
```

```{r}
library(corrplot)
col <- colorRampPalette(c("#4B0082", "#00FF00", "#FFA500", "#FF0000"))(100)
corrplot.mixed(cor(df[,categorical]), lower.col = col, upper.col = "grey", tl.col = "black",tl.cex=0.8, tl.srt=45,tl.pos = "lt", number.cex = 0.7)

```


